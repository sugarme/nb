{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import(\n",
    "    \"fmt\"\n",
    "    \n",
    "    \"github.com/sugarme/tokenizer/pretrained\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ids:\t\t[2182 2003 2054 2057 2024 2183 2000 4372 16044 1012]\n",
      "TypeIds:\t[0 0 0 0 0 0 0 0 0 0]\n",
      "Tokens:\t\t[\"here\" \"is\" \"what\" \"we\" \"are\" \"going\" \"to\" \"en\" \"##code\" \".\"]\n",
      "Offsets:\t[[0 4] [5 7] [8 12] [13 15] [16 19] [20 25] [26 28] [29 31] [31 35] [35 36]]\n",
      "Overflowing:\t[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16 <nil>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk := pretrained.BertBaseUncased()\n",
    "\n",
    "input := \"Here is what we are going to encode.\"\n",
    "\n",
    "e, err := tk.EncodeSingle(input)\n",
    "\n",
    "fmt.Printf(\"Ids:\\t\\t%v\\n\", e.Ids)\n",
    "fmt.Printf(\"TypeIds:\\t%v\\n\", e.TypeIds)\n",
    "fmt.Printf(\"Tokens:\\t\\t%q\\n\", e.Tokens)\n",
    "fmt.Printf(\"Offsets:\\t%v\\n\", e.Offsets)\n",
    "fmt.Printf(\"Overflowing:\\t%v\\n\", e.Overflowing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go",
   "language": "go",
   "name": "gophernotes"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
